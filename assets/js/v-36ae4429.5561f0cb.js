"use strict";(self.webpackChunkq10viking_github_io=self.webpackChunkq10viking_github_io||[]).push([[57838],{45257:(s,e,n)=>{n.r(e),n.d(e,{data:()=>o});const o={key:"v-36ae4429",path:"/kafka/01%20%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.html",title:"",lang:"zh-CN",frontmatter:{sidebarDepth:3,sidebar:"auto",prev:{text:"Back To 目录",link:"/kafka/"},"typora-root-url":"..\\.vuepress\\public"},excerpt:"",headers:[{level:2,title:"基本概念",slug:"基本概念",children:[{level:3,title:"主题Topic和消息日志Log",slug:"主题topic和消息日志log",children:[]},{level:3,title:"消费者位移主题",slug:"消费者位移主题",children:[]},{level:3,title:"Topic，Partition和Broker",slug:"topic-partition和broker",children:[]}]},{level:2,title:"集群",slug:"集群",children:[]},{level:2,title:"Producers",slug:"producers",children:[]},{level:2,title:"Consumers",slug:"consumers",children:[]},{level:2,title:"消费顺序",slug:"消费顺序",children:[]}],filePathRelative:"kafka/01 基本概念.md"}},42781:(s,e,n)=>{n.r(e),n.d(e,{default:()=>a});const o=(0,n(20641).Fv)('<h2 id="基本概念" tabindex="-1"><a class="header-anchor" href="#基本概念" aria-hidden="true">#</a> 基本概念</h2><ul><li><p>主题：Topic。主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。</p></li><li><p>分区：Partition。一个有序不变的消息序列。每个主题下可以有多个分区</p></li><li><p>消费者组：Consumer Group。多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。</p></li><li><p>消息位移：Offset。表示分区中每条消息的位置信息，是一个单调递增且不变的值。</p></li><li><p>消费者位移：Consumer Offset。表征消费者消费进度，每个消费者都有自己的消费者位移。</p></li></ul><p><img src="/images/kafka/image-20230421225112269.png" alt="image-20230421225112269"></p><h3 id="主题topic和消息日志log" tabindex="-1"><a class="header-anchor" href="#主题topic和消息日志log" aria-hidden="true">#</a> <strong>主题Topic和消息日志Log</strong></h3><p><strong>可以理解Topic是一个类别的名称，同类消息发送到同一个Topic下面。对于每一个Topic，下面可以有多个分区(Partition)日志文件</strong></p><p><img src="/images/kafka/122862.png" alt="https://note.youdao.com/yws/public/resource/b0357bdb4821ed2e35ecdbdacd65aa06/xmlnote/88B28CF6D35942F2B393E5A32632ABEC/122862"></p><ul><li>Partition是一个<strong>有序的message序列</strong>，这些message按顺序添加到一个叫做<strong>commit log的文件</strong>中。每个partition中的消息都有一个唯一的编号，称之为offset，用来唯一标示某个分区中的message</li><li><strong>每个partition，都对应一个commit log文件</strong>。一个partition中的message的offset都是唯一的，但是不同的partition中的message的offset可能是相同的。</li></ul><blockquote><p>test主题，分区test-0下的log文件</p></blockquote><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code>q10viking@LAPTOP-PJLAUUSP:~/software/kafka_2.12-2.5.0/kafka-logs/test-0$ <span class="token function">ls</span>\n00000000000000000000.index      00000000000000000007.snapshot\n00000000000000000000.log        leader-epoch-checkpoint\n</code></pre><div class="line-numbers"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><ul><li>kafka一般不会删除消息，不管这些消息有没有被消费。只会根据配置的日志保留时间(log.retention.hours)确认消息多久被删除，默认保留最近一周的日志消息。kafka的性能与保留的消息数据量大小没有关系，因此保存大量的数据消息日志信息不会有什么影响</li></ul><p><strong>每个consumer是基于自己在commit log中的消费进度(offset)来进行工作的</strong>。在kafka中，<strong>消费offset由consumer自己来维护</strong>；一般情况下我们按照顺序逐条消费commit log中的消息，当然我可以通过指定offset来重复消费某些消息，或者跳过某些消息。</p><p>这意味kafka中的consumer对集群的影响是非常小的，添加一个或者减少一个consumer，对于集群或者其他consumer来说，都是没有影响的，因为每个consumer维护各自的消费offset。</p><h3 id="消费者位移主题" tabindex="-1"><a class="header-anchor" href="#消费者位移主题" aria-hidden="true">#</a> 消费者位移主题</h3><blockquote><p>新版本 Consumer 的位移管理机制就是将 Consumer 的位移数据作为一条条普通的 Kafka 消息，提交到 __consumer_offsets 中。可以这么说，__consumer_offsets 的主要作用是保存 Kafka 消费者的位移信息。它要求这个提交过程不仅要实现高持久性，还要支持高频的写操作。</p></blockquote><p><img src="/images/kafka/image-20230422135104093.png" alt="image-20230422135104093"></p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code>q10viking@LAPTOP-PJLAUUSP:~/software/kafka_2.12-2.5.0/kafka-logs$ <span class="token function">ls</span>\n__consumer_offsets-0   __consumer_offsets-34\n__consumer_offsets-1   __consumer_offsets-35\n__consumer_offsets-10  __consumer_offsets-36\n__consumer_offsets-11  __consumer_offsets-37\n__consumer_offsets-12  __consumer_offsets-38\n__consumer_offsets-13  __consumer_offsets-39\n__consumer_offsets-14  __consumer_offsets-4\n__consumer_offsets-15  __consumer_offsets-40\n__consumer_offsets-16  __consumer_offsets-41\n__consumer_offsets-17  __consumer_offsets-42\n__consumer_offsets-18  __consumer_offsets-43\n__consumer_offsets-19  __consumer_offsets-44\n__consumer_offsets-2   __consumer_offsets-45\n__consumer_offsets-20  __consumer_offsets-46\n__consumer_offsets-21  __consumer_offsets-47\n__consumer_offsets-22  __consumer_offsets-48\n__consumer_offsets-23  __consumer_offsets-49\n__consumer_offsets-24  __consumer_offsets-5\n__consumer_offsets-25  __consumer_offsets-6\n__consumer_offsets-26  __consumer_offsets-7\n__consumer_offsets-27  __consumer_offsets-8\n__consumer_offsets-28  __consumer_offsets-9\n__consumer_offsets-29  cleaner-offset-checkpoint\n__consumer_offsets-3   log-start-offset-checkpoint\n__consumer_offsets-30  meta.properties\n__consumer_offsets-31  recovery-point-offset-checkpoint\n__consumer_offsets-32  replication-offset-checkpoint\n__consumer_offsets-33  test-0\n</code></pre><div class="line-numbers"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br></div></div><h3 id="topic-partition和broker" tabindex="-1"><a class="header-anchor" href="#topic-partition和broker" aria-hidden="true">#</a> <strong>Topic，Partition和Broker</strong></h3><p>一个topic，代表逻辑上的一个业务数据集，订单相关操作消息放入订单topic，用户相关操作消息放入用户topic，对于大型网站来说，后端数据都是海量的，订单消息很可能是非常巨量的，比如有几百个G甚至达到TB级别，如果把这么多数据都放在一台机器上可定会有容量限制问题，那么就可以在topic内部划分多个partition来分片存储数据，不同的partition可以位于不同的机器上，每台机器上都运行一个Kafka的进程Broker。</p><p><strong>为什么要对Topic下数据进行分区存储？</strong></p><ol><li><p>commit log文件会受到所在机器的文件系统大小的限制，分区之后可以将不同的分区放在不同的机器上，相当于对数据做了<strong>分布式存储</strong>，理论上一个topic可以处理任意数量的数据。</p></li><li><p>为了<strong>提高并行度</strong>。</p></li></ol><h2 id="集群" tabindex="-1"><a class="header-anchor" href="#集群" aria-hidden="true">#</a> 集群</h2><p><img src="/images/kafka/122860.png" alt="https://note.youdao.com/yws/public/resource/b0357bdb4821ed2e35ecdbdacd65aa06/xmlnote/EA60D4B78E4E4791B30A5B8507EBC132/122860"></p><h2 id="producers" tabindex="-1"><a class="header-anchor" href="#producers" aria-hidden="true">#</a> <strong>Producers</strong></h2><p>生产者将消息发送到topic中去，同时负责选择将message发送到topic的哪一个partition中。通过round-robin做简单的负载均衡。也可以根据消息中的某一个关键字来进行区分。通常第二种方式使用的更多。</p><h2 id="consumers" tabindex="-1"><a class="header-anchor" href="#consumers" aria-hidden="true">#</a> <strong>Consumers</strong></h2><p>传统的消息传递模式有2种：队列( queue) 和（publish-subscribe）</p><ul><li>queue模式：多个consumer从服务器中读取数据，消息只会到达一个consumer。</li><li>publish-subscribe模式：消息会被广播给所有的consumer。</li></ul><p>Kafka基于这2种模式提供了一种consumer的抽象概念：consumer group。</p><ul><li>queue模式：所有的consumer都位于同一个consumer group 下。</li><li>publish-subscribe模式：所有的consumer都有着自己唯一的consumer group。</li></ul><p><img src="/images/kafka/122857.png" alt="https://note.youdao.com/yws/public/resource/b0357bdb4821ed2e35ecdbdacd65aa06/xmlnote/B579E116B1F047F6A6A563255D361013/122857"></p><p>由2个broker组成的kafka集群，某个主题总共有4个partition(P0-P3)，分别位于不同的broker上。这个集群由2个Consumer Group消费， A有2个consumer instances ，B有4个。</p><p>通常一个topic会有几个consumer group，每个consumer group都是一个逻辑上的订阅者（ logical subscriber ）。每个consumer group由多个consumer instance组成，从而达到可扩展和容灾的功能。</p><h2 id="消费顺序" tabindex="-1"><a class="header-anchor" href="#消费顺序" aria-hidden="true">#</a> <strong>消费顺序</strong></h2><p>一个partition同一个时刻在一个consumer group中只能有一个consumer instance在消费，从而保证消费顺序。</p><p><strong>consumer group中的consumer instance的数量不能比一个Topic中的partition的数量多，否则，多出来的consumer消费不到消息。</strong></p><p>Kafka只在partition的范围内保证消息消费的局部顺序性，不能在同一个topic中的多个partition中保证总的消费顺序性。</p><p>如果有在总体上保证消费顺序的需求，那么我们可以通过将topic的partition数量设置为1，将consumer group中的consumer instance数量也设置为1，但是这样会影响性能，所以kafka的顺序消费很少用。</p>',37),r={},a=(0,n(66262).A)(r,[["render",function(s,e){return o}]])},66262:(s,e)=>{e.A=(s,e)=>{const n=s.__vccOpts||s;for(const[s,o]of e)n[s]=o;return n}}}]);